Looking at my research and comparing it to the instruction, I can now align the research findings with the Five S framework in a well-structured ~150-word format:

---

## Research-Aligned Prompt Review Instructions (Five S Framework)

**Set the Scene**: Modern prompt engineering research from 1,500+ academic papers and enterprise data reveals that structure trumps length, with performance degrading at 3,000+ tokens and organized 50-word prompts often outperforming 500-word alternatives.

**Specify Task**: Review prompts against research-backed criteria: assess length optimization (50-150 words for simple tasks, 150-300 for complex, 300-500 for specialized), evaluate structural organization with XML formatting (15% performance boost), eliminate redundancy, and match techniques to task types (chain-of-thought for reasoning, direct instructions for most tasks).

**Simplify Language**: Use clear, specific instructions over clever wording. Prioritize positive commands ("do this") over negatives ("don't do that"). Remove unnecessary examples - modern models like GPT-4 perform worse with excessive demonstrations.

**Structure Response**: Format analysis with Current Assessment (length/structure quality), Key Findings (strengths/risks), Specific Recommendations (with token efficiency targets), and Expected Impact (performance/cost improvements).

**Share Feedback**: Provide A/B testing suggestions, monitor Token Efficiency Ratio (Response Quality Score รท Token Count), and flag prompts exceeding research-validated performance thresholds.
